{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%script echo skipping....\n",
    "%conda install jupyter pytorch\n",
    "%pip install 'git+https://github.com/deepset-ai/haystack.git#main' sentence-transformers 'txtai[pipeline-data]' qdrant-haystack gradio"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4db73c900e37f9c4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%script echo skipping.....\n",
    "!docker run --rm -p 6333:6333 -p 6334:6334 -v $(pwd)/qdrant_storage:/qdrant/storage:z -d qdrant/qdrant\n",
    "!docker run -d -p 9998:9998 apache/tika:latest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f713acb039d5fe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from haystack import Pipeline, Document\n",
    "from haystack.components.builders import DynamicChatPromptBuilder\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder, SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.preprocessors import DocumentCleaner\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.writers.document_writer import DuplicatePolicy\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from qdrant_haystack import QdrantDocumentStore\n",
    "from qdrant_haystack.retriever import QdrantRetriever\n",
    "from txtai.pipeline import Textractor\n",
    "\n",
    "document_store = QdrantDocumentStore(\n",
    "    \":memory:\",#\"http://127.0.0.1\",\n",
    "    recreate_index=True,\n",
    "    return_embedding=True,\n",
    "    wait_result_from_api=True,\n",
    "    index='zarathustra-rag2a'\n",
    ")\n",
    "\n",
    "document_embedder = SentenceTransformersDocumentEmbedder(\n",
    "    model_name_or_path=\"BAAI/llm-embedder\",\n",
    "    prefix=\"Represent this document for retrieval: \"\n",
    ")\n",
    "document_embedder.warm_up()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8501ec8708cd5e0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %%script echo skipping....\n",
    "documents = []\n",
    "textract = Textractor(paragraphs=True)\n",
    "for paragraph in textract(\"zarathustra-critical-guide.html\"):\n",
    "    if len(paragraph) > 32:\n",
    "        documents.append(\n",
    "            Document(\n",
    "                meta={'name': \"Nietzsche's 'Thus Spoke Zarathustra': A Critical Guide\"},\n",
    "                content=paragraph\n",
    "            )\n",
    "        )\n",
    "\n",
    "for paragraph in textract(\"zarathustra.md\"):\n",
    "    if len(paragraph) > 32:\n",
    "        documents.append(\n",
    "            Document(\n",
    "                meta={'name': \"Thus Spoke Zarathustra\"},\n",
    "                content=paragraph\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39582302672af1b9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "document_writer = DocumentWriter(document_store = document_store)\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_component(instance=DocumentCleaner(), name=\"cleaner\")\n",
    "indexing_pipeline.add_component(instance=document_embedder, name=\"embedder\")\n",
    "indexing_pipeline.add_component(instance=document_writer, name=\"writer\")\n",
    "indexing_pipeline.connect(\"cleaner\", \"embedder\")\n",
    "indexing_pipeline.connect(\"embedder\", \"writer\")\n",
    "indexing_pipeline.draw(\"indexing_pipeline.png\")\n",
    "indexing_pipeline.warm_up()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed447e0227c4eb52",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %%script echo skipping.......\n",
    "indexing_pipeline.run(\n",
    "    {\n",
    "        \"cleaner\": {\n",
    "            \"documents\": documents\n",
    "        },\n",
    "        \"writer\": {\n",
    "            \"policy\": DuplicatePolicy.OVERWRITE\n",
    "        }\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d20d4e2223db7cf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "retriever = QdrantRetriever(\n",
    "    document_store=document_store,\n",
    "    top_k=10\n",
    ")\n",
    "\n",
    "text_embedder = SentenceTransformersTextEmbedder(\n",
    "        model_name_or_path=\"BAAI/llm-embedder\",\n",
    "        prefix=\"Represent this query for retrieving relevant documents: \"\n",
    "    )\n",
    "\n",
    "template = \"\"\"\n",
    "Given the following information, follow my instruction.\n",
    "\n",
    "Context: \n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "My Instruction: {{ question }}\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = DynamicChatPromptBuilder(runtime_variables=[\"documents\"])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e926fd2c0dee969",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from time import sleep\n",
    "\n",
    "class QueueIterator:\n",
    "    def __init__(self):\n",
    "        self.queue = deque()\n",
    "\n",
    "    def add(self, item):\n",
    "        self.queue.append(item)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        retry_countdown = 60\n",
    "        while retry_countdown > 0:\n",
    "            popped = self.pop()\n",
    "            if not popped:\n",
    "                retry_countdown -= 1\n",
    "                sleep(10)\n",
    "            else:\n",
    "                return popped\n",
    "        raise StopIteration\n",
    "\n",
    "    def pop(self):\n",
    "        if self.queue:\n",
    "            return self.queue.popleft()\n",
    "        else:\n",
    "            return False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7125103fbc84b300",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "qi = QueueIterator()\n",
    "llm = OpenAIChatGenerator(streaming_callback=lambda chunk: qi.add(chunk.content),api_base_url=\"\", api_key=\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5841b1e48b08a373",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "rag_pipeline.add_component(\"retriever\", retriever)\n",
    "rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "rag_pipeline.add_component(\"llm\", llm)\n",
    "rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "rag_pipeline.draw(\"rag_pipeline.png\")\n",
    "rag_pipeline.warm_up()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dcb851e168351b7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def send(message, history):\n",
    "    def really_send_for_real():\n",
    "        messages = [ChatMessage.from_user(template)]\n",
    "        response = rag_pipeline.run(\n",
    "            {\n",
    "                \"text_embedder\": {\"text\": message},\n",
    "                \"prompt_builder\": {\n",
    "                    \"template_variables\": {\"question\": message},\n",
    "                    \"prompt_source\": messages\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    return really_send_for_real\n",
    "import multiprocessing\n",
    "\n",
    "def send_and_return(message, history):\n",
    "    p = multiprocessing.Process(target=send(message, history))\n",
    "    p.start()\n",
    "    return qi\n",
    "\n",
    "# print(send(\"Who is zarathustra?\", None))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31bbb1e3449df95a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %%script echo skipping....\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "demo = gr.ChatInterface(fn=send_and_return, title=\"RAG2A\")\n",
    "demo.launch(inline=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "685026113ddc7614",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "rag-2a",
   "language": "python",
   "display_name": "RAG 2A"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
